# Keyframe Extraction
# input arguments:
# 1: video location


import scipy.io
import sys
import os
import math
import copy
from sklearn.cluster import KMeans
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
from collections import namedtuple
import time
from sampling import *
from func_VSUMM import *
from func_SBD import *
from histogramsummary import *
from func_SIFT import *
from histogramblockclustering import *


def extract_from_indices(selection, frame_count, path, savepath):
    # extracts keyframes from selected indices summary
    cap = cv2.VideoCapture(os.path.abspath(os.path.expanduser(path)))
    try:
        if not os.path.exists(savepath):
            os.makedirs(savepath)
    except OSError:
        print("Error cant make directory")

    print("extracting frames")
    for i in range (0, frame_count):
        if(selection[i]):
            #print("extracting frame " + str(i))
            cap.set(cv2.CAP_PROP_POS_FRAMES, i)
            ret, frame = cap.read()
            name = savepath + '/' + str(i) + '.jpg'
            cv2.imwrite(name, frame)

def random_summary(compression, n_frames):
    print("Generating random summary")
    summary_selections = np.random.random((n_frames, 1)) * 100
    val_percentile = np.percentile(summary_selections, compression)
    sumsel = np.zeros([n_frames, 1])
    for i in range(0, len(summary_selections)):
        if summary_selections[i] >= val_percentile:
            sumsel[i] = 1
    return sumsel

def VSUMM(path_in, sample_rate, summ_percent, hist):

    global num_bins, sampling_rate, percent, num_centroids
    num_bins = 16

    # size of values in each bin
    range_per_bin = 256 / num_bins

    # frame chosen every k frames
    sampling_rate = sample_rate

    # number of centroids
    percent = summ_percent

    # globalizing
    num_centroids = 0


    print("Opening video!")
    video = imageio.get_reader(path_in)
    vidcap = cv2.VideoCapture(path_in)
    frame_count = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)
    print("Video opened\nChoosing frames")
    print(len(video))
    print(frame_count)
    # choosing the subset of frames from which video summary will be generateed
    frames = [video.get_data(i * sampling_rate) for i in range(int(frame_count / sampling_rate))]
    print("Frames chosen")
    print("Length of video %d" % frame_count)

    # converting percentage to actual number
    num_centroids = int(percent * frame_count / 100)
    if (frame_count / sampling_rate) < num_centroids:
        print("Samples too less to generate such a large summary")
        print("Changing to maximum possible centroids")
        num_centroids = frame_count / sampling_rate

    if hist == 1:
        print("Generating 3D Tensor Histrograms")
        # manually generated histogram
        color_histogram = [generate_histogram(frame) for frame in frames]
        print("Color Histograms generated")

    # opencv: generates 3 histograms corresponding to each channel for each frame
    print("Generating linear Histrograms using OpenCV")
    channels = ['b', 'g', 'r']
    hist = []
    for frame in frames:
        feature_value = [cv2.calcHist([frame], [i], None, [num_bins], [0, 256]) for i, col in enumerate(channels)]
        hist.append(np.asarray(feature_value).flatten())
    hist = np.asarray(hist)
    print("Done generating!")
    print("Shape of histogram: " + str(hist.shape))

    # clustering: defaults to using the histogram generated by OpenCV
    print("Clustering")

    # choose number of centroids for clustering from user required frames (specified in GT folder for each video)
    if percent == -1:
        video_address = sys.argv[1].split('/')
        gt_file = video_address[len(video_address) - 1].split('.')[0] + '.mat'
        video_address[len(video_address) - 1] = gt_file
        video_address[len(video_address) - 2] = 'GT'
        gt_file = '/'.join(video_address)
        num_frames = int(scipy.io.loadmat(gt_file).get('user_score').shape[0])
        # automatic summary sizing: summary assumed to be 1/100 of original video
        num_centroids = int(0.1 * num_frames)

    kmeans = KMeans(n_clusters=num_centroids).fit(hist)
    print("Done Clustering!")

    print("Generating summary frames")
    summary_frames = []

    # transforms into cluster-distance space (n_cluster dimensional)
    hist_transform = kmeans.transform(hist)
    frame_indices = []
    for cluster in range(hist_transform.shape[1]):
        print("Frame number: %d" % (np.argmin(hist_transform.T[cluster]) * sampling_rate))
        frame_indices.append(np.argmin(hist_transform.T[cluster]))

    # frames generated in sequence from original video
    frame_indices = sorted(frame_indices)
    summary_frames = [frames[i] for i in frame_indices]
    print("Generated summary")

    out_array = save_keyframes(frame_indices, frame_count)
    return out_array

def SBD(video_path):

    __hist_size__ = 128  # how many bins for each R,G,B histogram
    __min_duration__ = 10  # if a shot has length less than this, merge it with others
    __absolute_threshold__ = 100000  # any transition must be no less than this threshold


    shots = []
    min_duration = __min_duration__
    detector = shotDetector(video_path)
    scores, hists, frames = detector.run()

    # detector.pick_frame(sys.argv[2], sys.argv[3])

    print("hoi")
    print(len(detector.scores))
    print("frame_count is {0}".format(detector.frame_count))

    average_frame_div = sum(detector.scores) / len(detector.scores)
    print("average divergence = {0}".format(average_frame_div))

    special_frame = [sp_frame for sp_frame in detector.scores if sp_frame > average_frame_div * detector.factor]

    print("special frames have {0}".format(len(special_frame)))

    print("max diff:", max(scores), "min diff:", min(scores))
    # compute automatic threshold
    mean_score = np.mean(scores)
    std_score = np.std(scores)
    threshold = max(__absolute_threshold__, mean_score + 3 * std_score)
    print("thresh")
    print(threshold)
    # decide shot boundaries
    prev_i = 0
    prev_score = scores[0]
    for i, score in enumerate(scores[1:]):
        if score >= threshold and abs(score - prev_score) >= threshold / 2.0:
            shots.append((prev_i, i + 2))
            prev_i = i + 2
        prev_score = score
    video_length = len(hists)
    shots.append((prev_i, video_length))
    assert video_length >= min_duration, "duration error"

    #merge_short_shots(shots, min_duration)

    # save key frames
    out_array = list(zip(*shots))
    out_array = out_array[0]
    return out_array


def SIFT(fileName):

    videoCap = cv2.VideoCapture(fileName)
    fps = videoCap.get(cv2.CAP_PROP_FPS)
    print("Frames per second: ", fps)
    euclideanDistance = []


    i = 0
    success, image = videoCap.read()
    height = len(image)
    width = len(image[0])
    totalPixels = width * height
    while success:
        grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        histogram = cv2.calcHist([grayImage], [0], None, [256], [0, 256])
        colorMoments = getColorMoments(histogram, totalPixels)

        if i == 0:
            euclideanDistance.append(0)
        else:
            euclideanDistance.append(getEuclideanDistance(colorMoments, prevColorMoments))

        prevColorMoments = colorMoments

        i += 1
        success, image = videoCap.read()
        # Uncomment this for breaking early i.e. 100 frames
        # if i==50:
        #     break

    perc = 0.05
    keyFramesIndices = sorted(np.argsort(euclideanDistance)[::-1][:int(i * perc)])
    print(keyFramesIndices)
    return keyFramesIndices




if __name__ == '__main__':
    print("Path:")
    print(sys.argv[1])
    #cap = cv2.VideoCapture(os.path.abspath(os.path.expanduser(sys.argv[1])))
    #frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    #print("Frame count: " + str(frame_count))
    start_time = time.time()
    print("Block clustering time: --- %s seconds ---" % (time.time() - start_time))
    #keyframe_indices, framesdata = blockclustering(sys.argv[1])

    # generate randomy summary
    #summ = random_summary(99.9, frame_count) # compression percentage as argument
    #print("Generated summary:")
    #print(summ)
    #summ = histogram_summary(sys.argv[1],0.3, frame_count)
    #extract_from_indices(summ, frame_count, sys.argv[1], 'keyframes')
    #print(summ)
    #summ1 = uniform_sampling_summary(frame_count, 98.3)

    #summ1 = uniform_sampling_summary(frame_count, 99.7)
    #print(summ1)


    #summ3 = VSUMM(sys.argv[1], 1, 10, 0)
    #summ4 = SBD(sys.argv[1])
    #print(summ4)
    #summ5 = SIFT(sys.argv[1])

    # extract keyframes from summary
    #extract_from_indices(summ1)

    #summ3 = VSUMM(sys.argv[1], 1, 10, 0)

    #extract keyframes from summary

    #extract_from_indices(summ, frame_count, sys.argv[1], 'keyframes')

